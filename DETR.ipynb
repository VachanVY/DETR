{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Py Imports\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# DL Imports\n",
    "import tensorflow as tf\n",
    "import keras_cv as nn_cv\n",
    "# from tensorflow_addons.optimizers import MultiOptimizer\n",
    "nn = tf.keras\n",
    "tnp = tf.experimental.numpy\n",
    "\n",
    "# Project Imports\n",
    "from dataset import load_pascal_voc\n",
    "from backbone import BackBone\n",
    "from detr_transformer import Transformer\n",
    "from feedforward import FFN\n",
    "from matcher import Matcher\n",
    "from loss import HungarianLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PASCAL VOC 2007\n",
    "\n",
    "PASCAL VOC 2007 is a dataset for image recognition. The twenty object classes that have been selected are:\n",
    "\n",
    "    \n",
    "```python\n",
    "classes =  {\n",
    "  Person: [person],\n",
    "  Animal: [bird, cat, cow, dog, horse, sheep],\n",
    "  Vehicle: [aeroplane, bicycle, boat, bus, car, motorbike, train],\n",
    "  Indoor: [bottle, chair, dining table, potted plant, sofa, tv/monitor]\n",
    "  }\n",
    "```\n",
    "\n",
    "We add an extra class `no_object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = [\n",
    "    \"no_object\",\n",
    "    \"Aeroplane\",\n",
    "    \"Bicycle\",\n",
    "    \"Bird\",\n",
    "    \"Boat\",\n",
    "    \"Bottle\",\n",
    "    \"Bus\",\n",
    "    \"Car\",\n",
    "    \"Cat\",\n",
    "    \"Chair\",\n",
    "    \"Cow\",\n",
    "    \"Dining Table\",\n",
    "    \"Dog\",\n",
    "    \"Horse\",\n",
    "    \"Motorbike\",\n",
    "    \"Person\",\n",
    "    \"Potted Plant\",\n",
    "    \"Sheep\",\n",
    "    \"Sofa\",\n",
    "    \"Train\",\n",
    "    \"Tv/monitor\",\n",
    "    ]\n",
    "\n",
    "print(\"number of classes is\", len(class_ids))\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETR and Train Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DETR_ARGS:\n",
    "    N:int = 42 # max number of bboxes which can be present in an image\n",
    "    n_classes:int = len(class_ids)\n",
    "\n",
    "    max_length:list = [256, N] # [encoder:max((H*W) in images), decoder:max(num_object in images)]\n",
    "    d_model:int = 1024\n",
    "    n_heads:int = 8\n",
    "    n_enc_layers:int = 2\n",
    "    n_dec_layers:int = 3\n",
    "    dropout_rate:float = 0.1\n",
    "    \n",
    "    backbone_lr:float = 1e-5\n",
    "    weight_decay:float = 1e-4\n",
    "    transformer_lr:float = 1e-4\n",
    "    epochs:int = 1 # to be changed\n",
    "    batch_size:int = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n",
    "  inputs = next(iter(inputs.take(1)))\n",
    "  images, bounding_boxes = inputs[0], {\"classes\": inputs[1][0], \"boxes\": inputs[1][1]}\n",
    "  nn_cv.visualization.plot_bounding_box_gallery(\n",
    "      images,\n",
    "      value_range=value_range,\n",
    "      rows=rows,\n",
    "      cols=cols,\n",
    "      y_true=bounding_boxes,\n",
    "      scale=5,\n",
    "      font_scale=0.7,\n",
    "      bounding_box_format=bounding_box_format,\n",
    "      class_mapping=class_mapping,\n",
    "  )\n",
    "\n",
    "train_ds = load_pascal_voc(split=\"test\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"); print(tf.data.experimental.cardinality(train_ds))\n",
    "val_ds = load_pascal_voc(split=\"validation\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"); print(tf.data.experimental.cardinality(val_ds))\n",
    "test_ds = load_pascal_voc(split=\"train\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"); print(tf.data.experimental.cardinality(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    N = DETR_ARGS.N\n",
    "    X = nn_cv.layers.Resizing(500, 500, bounding_box_format=\"xywh\", pad_to_aspect_ratio=True)(x[\"images\"])\n",
    "    y = (\n",
    "        tf.pad([x[\"bounding_boxes\"][\"classes\"]], [[0,0], [N,N]])[0][N:-len(x[\"bounding_boxes\"][\"classes\"])],\n",
    "        tf.pad(x[\"bounding_boxes\"][\"boxes\"], [[N,N], [0,0]])[N:-len(x[\"bounding_boxes\"][\"boxes\"])]\n",
    "    )\n",
    "    return X, y\n",
    "\n",
    "train_ds = train_ds.map(preprocess)\n",
    "val_ds = val_ds.map(preprocess)\n",
    "test_ds = test_ds.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(train_ds.ragged_batch(4, drop_remainder=True), \n",
    "                  bounding_box_format=\"xywh\", \n",
    "                  value_range=(0, 255), \n",
    "                  rows=2, cols=2\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(val_ds.ragged_batch(4, drop_remainder=True), \n",
    "                  bounding_box_format=\"xywh\", \n",
    "                  value_range=(0, 255), \n",
    "                  rows=2, cols=2\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(test_ds.ragged_batch(4, drop_remainder=True), \n",
    "                  bounding_box_format=\"xywh\", \n",
    "                  value_range=(0, 255), \n",
    "                  rows=2, cols=2\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_bbox(x, y):\n",
    "    img = x\n",
    "    cls = y[0]\n",
    "    box = y[1]/500\n",
    "    return img, (cls, box)\n",
    "\n",
    "def denormalize_bbox(x, y):\n",
    "    img = x\n",
    "    cls = y[0]\n",
    "    box = y[1]*500\n",
    "    return img, (cls, box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda x, y: normalize_bbox(x, y))\n",
    "val_ds = val_ds.map(lambda x, y: normalize_bbox(x, y))\n",
    "test_ds = test_ds.map(lambda x, y: normalize_bbox(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DETR(nn.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.backbone = BackBone(\n",
    "            DETR_ARGS.d_model, \n",
    "        )\n",
    "        self.transformer = Transformer(\n",
    "            DETR_ARGS.d_model, \n",
    "            DETR_ARGS.n_heads, \n",
    "            DETR_ARGS.n_enc_layers, \n",
    "            DETR_ARGS.n_dec_layers, \n",
    "            DETR_ARGS.dropout_rate, \n",
    "            DETR_ARGS.max_length, \n",
    "        )\n",
    "        self.ffn = FFN(\n",
    "            DETR_ARGS.d_model, \n",
    "            DETR_ARGS.n_classes\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        if not training: # when training==False excecute below line\n",
    "            inputs = nn_cv.layers.Resizing(500, 500, bounding_box_format=\"xywh\", pad_to_aspect_ratio=True)(inputs)\n",
    "        x = self.backbone(inputs, training=training)\n",
    "        x = self.transformer(x, training=training)\n",
    "        class_prob, bbox_pred = self.ffn(x, training=training) # ((B, N, 4), (B, N, 4))\n",
    "        return (class_prob, bbox_pred) # ((B, N, n_classes), (B, N, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DETR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers_layers = [\n",
    "#     (tf.optimizers.AdamW(learning_rate=1e-5, weight_decay=DETR_ARGS.weight_decay), model.layers[0]), \n",
    "#     (tf.optimizers.AdamW(learning_rate=1e-4, weight_decay=DETR_ARGS.weight_decay), model.layers[1:])]\n",
    "optimizer = tf.optimizers.AdamW(learning_rate=5.5e-5, weight_decay=DETR_ARGS.weight_decay) #MultiOptimizer(optimizers_layers)\n",
    "\n",
    "loss_fn = HungarianLoss(name=\"hugarian_loss\")\n",
    "matcher = Matcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(jit_compile=True)\n",
    "def train_step(train_ds):\n",
    "    loss_values = []\n",
    "    for step, (x_train, y_train) in enumerate(train_ds):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_train, training=True)\n",
    "            y_pred = matcher(y_train, y_pred)\n",
    "            loss = loss_fn(y_train, y_pred)\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        loss_values.append(loss)\n",
    "        print(\"Training loss (for one batch) at step %d: %.4f\" % (step, float(loss)))\n",
    "        print(\"Seen so far: %s samples\" % ((step + 1) * DETR_ARGS.batch_size))\n",
    "    return tf.reduce_mean(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, DETR_ARGS.epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{DETR_ARGS.epochs}\")\n",
    "    loss = train_step(train_ds)\n",
    "    print(f\"Loss at Epoch {epoch} : {loss}\\n\")\n",
    "    model.save_weights(f'detr_weights_epoch{epoch}.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
